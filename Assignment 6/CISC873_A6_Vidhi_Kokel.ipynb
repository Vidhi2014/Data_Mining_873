{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Vidhi Kokel\n",
    "# Understand the template\n",
    "\n",
    "#### What is the experimental protocol used and how was it carried out? How did we tune hyper-parameters in the template? What is the search space and what is the criteria to determine good/bad hyper-parameters?\n",
    "#### ‚úÖThe experimental protocols used here are a combination of following layers combined in a sequential model with multiple layers. \n",
    "1. Embedding Layer\n",
    "2. LSTM Layer\n",
    "3. GRU Layer\n",
    "4. Bidirectional LSTM Layer\n",
    "5. Birdirectional GRU Layer\n",
    "6. Convolutional Layer\n",
    "7. Max Pooling Layer\n",
    "8. Fully Connected Layer\n",
    "\n",
    "#### The search space for the experiment is various hyper-parameters that can affect the performance of the model which are listed below.\n",
    "1. Number of Hidden layers and units\n",
    "2. Different types of layers\n",
    "3. Weight Initialization\n",
    "4. Activation functions\n",
    "5. Learning Rate\n",
    "6. Number of epochs\n",
    "7. Batch size\n",
    "\n",
    "#### The template shows how a multi-modality (both text and image inputs) multi-objective (predicting both price and type) solution can be provided for the current problem by using Embedding and reduced_mean layers for text inputs and a convolutional layer with max pooling for the image inputs. The loss weights have been set in the template. The criteria to decide good/bad hyper-parameters depends on how well the neural network is able to learn. It should not under-fit or overfit.\n",
    "\n",
    "# Problem Definition\n",
    "#### Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?\n",
    "#### ‚úÖWe are given the textual summary and images of multiple air bnb listings in Montreal in 2019. From these summaries and images we have to classify the type of the listing as well as the price category in which the property belongs to. There are following 3 sets of inputs used accross all the experiments. \n",
    "\n",
    "- Text(summary) + Image\n",
    "- Text(summary) only\n",
    "- Image only\n",
    "\n",
    "#### Moreover, there are following 3 sets of outputs representing the type and price category of the property listing that are possible from the above experiments. But since we have to find out the price in our problem, I have only used price prediction for submitting the solutions on Kaggle.\n",
    "\n",
    "- Price + Type\n",
    "- Price only\n",
    "- Type only\n",
    "\n",
    "#### Classification is required for this problem. The challenges could be the image resolution, unclear summary and not clean textual summary. The impact might be misclassification of the types and prices leading to false positives or false negatives. The ideal solution is a classification algorithm that accurately identifies the price and type categories for a given listing.\n",
    "\n",
    "# Theoretical Questions\n",
    "\n",
    "#### üåàBased on the provided template, describe the format of the input file (sdf file).\n",
    "#### üåàWhat are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?\n",
    "#### üåàFor each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?\n",
    "#### üåàWhat is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n",
    "#### üåàWhat is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n",
    "#### ‚úÖFor sequential data fully-connected model is a good model\n",
    "#### Because they are ‚Äústructure agnostic.‚Äù That is, no special assumptions need to be made about the inputs.\n",
    "##### Source: \n",
    "\n",
    "\n",
    "# Trial Discussion\n",
    "\n",
    "#### ‚úÖ‚úÖ‚úÖ‚úÖHere from all the 5 approaches, multi modality implementations outperform the implementations using only text inputs and that using only text inputs outperform the implementation that uses only image inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SDF format data (structured-data format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def read_sdf(file):\n",
    "    with open(file, 'r') as rf:\n",
    "        content = rf.read()\n",
    "    samples = content.split('$$$$')\n",
    "    \n",
    "    def parse_sample(s):\n",
    "        lines = s.splitlines()\n",
    "        links = []\n",
    "        nodes = []\n",
    "        label = 0\n",
    "        for l in lines:\n",
    "            if l.strip() == '1.0':\n",
    "                label = 1\n",
    "            if l.strip() == '-1.0':\n",
    "                label = 0\n",
    "            if l.startswith('    '):\n",
    "                feature = l.split()\n",
    "                node = feature[3]\n",
    "                nodes.append(node)\n",
    "            elif l.startswith(' '):\n",
    "                lnk = l.split()\n",
    "                # edge: (from, to,) (1-based index)\n",
    "                if int(lnk[0]) - 1 < len(nodes):\n",
    "                    links.append((\n",
    "                        int(lnk[0])-1, \n",
    "                        int(lnk[1])-1, # zero-based index\n",
    "                        # int(lnk[2]) ignore edge weight\n",
    "                    ))\n",
    "        return nodes, np.array(links), label\n",
    "    \n",
    "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9de9bc909a4fcb8c4b7677ebf241f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_set = read_sdf('train.sdf')\n",
    "training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d8c5877777421f84fb491b32bcf5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_set  = read_sdf('test_x.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['S', 'O', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 13],\n",
      "       [ 0, 14],\n",
      "       [ 1, 16],\n",
      "       [ 2, 17],\n",
      "       [ 3, 20],\n",
      "       [ 4, 21],\n",
      "       [ 5, 22],\n",
      "       [ 6, 23],\n",
      "       [ 7, 11],\n",
      "       [ 7, 12],\n",
      "       [ 7, 13],\n",
      "       [ 8, 13],\n",
      "       [ 8, 15],\n",
      "       [ 9, 15],\n",
      "       [ 9, 21],\n",
      "       [ 9, 26],\n",
      "       [10, 20],\n",
      "       [10, 21],\n",
      "       [10, 27],\n",
      "       [11, 14],\n",
      "       [11, 16],\n",
      "       [12, 15],\n",
      "       [12, 20],\n",
      "       [14, 17],\n",
      "       [16, 18],\n",
      "       [17, 19],\n",
      "       [18, 19],\n",
      "       [18, 22],\n",
      "       [19, 23],\n",
      "       [22, 24],\n",
      "       [23, 25],\n",
      "       [24, 25]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in training_set:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing/Inspecting a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install --quiet networkx\n",
    "# !pip install --user --quiet decorator==4.3.0\n",
    "\n",
    "# !pip install --user --quiet networkx==2.3\n",
    "# !pip install --user --quiet matplotlib==2.2.3\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import cm\n",
    "# colors = cm.rainbow(np.linspace(0, 1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize(sample):\n",
    "#     G=nx.Graph()\n",
    "#     nodes = sample[0]\n",
    "#     edges = sample[1]\n",
    "    \n",
    "#     labeldict={}\n",
    "#     node_color=[]\n",
    "#     for i,n in enumerate(nodes):\n",
    "#         G.add_node(i)\n",
    "#         labeldict[i]=n\n",
    "#         node_color.append(colors[hash(n)%len(colors)])\n",
    "\n",
    "#     # a list of nodes:\n",
    "#     for e in edges:\n",
    "#         G.add_edge(e[0], e[1])\n",
    "        \n",
    "#     nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
    "#     plt.show()\n",
    "    \n",
    "#     return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# visualize(training_set[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_vocab = 500\n",
    "max_len = 100\n",
    "\n",
    "\n",
    "# build vocabulary from training set\n",
    "all_nodes = [s[0] for s in training_set]\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def prepare_single_batch(samples):\n",
    "    sample_nodes = [s[0] for s in samples]\n",
    "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
    "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
    "    max_nodes_len = np.shape(sample_nodes)[1]\n",
    "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
    "    edges = [e for e in edges if len(e) > 0]\n",
    "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
    "    \n",
    "    all_nodes = np.reshape(sample_nodes, -1)\n",
    "    all_edges = np.concatenate(edges)\n",
    "\n",
    "    node_to_graph = np.reshape(node_to_graph, -1)\n",
    "    return {\n",
    "        'data': all_nodes,\n",
    "        'edges': all_edges,\n",
    "        'node2grah': node_to_graph,\n",
    "    }, np.array([s[2] for s in samples])\n",
    "\n",
    "\n",
    "\n",
    "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
    "    while True:\n",
    "        dataset = list(dataset)\n",
    "        if shuffle:\n",
    "            random.shuffle(dataset)\n",
    "        l = len(dataset)\n",
    "        for ndx in range(0, l, batch_size):\n",
    "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
    "            yield prepare_single_batch(batch_samples)\n",
    "        if not repeat:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "[2 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 4 2 2 2 2 3 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 4 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 6 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "edges\n",
      "[[ 0 12]\n",
      " [ 0 18]\n",
      " [ 1  2]\n",
      " [ 1  8]\n",
      " [ 1 10]\n",
      " [ 2  3]\n",
      " [ 3  9]\n",
      " [ 4  8]\n",
      " [ 4 13]\n",
      " [ 5 11]\n",
      " [ 5 13]\n",
      " [ 6 11]\n",
      " [ 7 13]\n",
      " [ 8  9]\n",
      " [ 9 11]\n",
      " [10 12]\n",
      " [10 14]\n",
      " [12 15]\n",
      " [14 16]\n",
      " [15 17]\n",
      " [16 17]\n",
      " [25 33]\n",
      " [25 41]\n",
      " [26 36]\n",
      " [27 36]\n",
      " [28 30]\n",
      " [29 30]\n",
      " [30 34]\n",
      " [31 33]\n",
      " [31 35]\n",
      " [31 36]\n",
      " [32 34]\n",
      " [32 35]\n",
      " [32 37]\n",
      " [33 38]\n",
      " [34 39]\n",
      " [37 40]\n",
      " [38 42]\n",
      " [39 43]\n",
      " [40 43]\n",
      " [41 42]\n",
      " [50 54]\n",
      " [50 55]\n",
      " [51 69]\n",
      " [52 54]\n",
      " [52 56]\n",
      " [53 62]\n",
      " [53 68]\n",
      " [54 57]\n",
      " [55 56]\n",
      " [55 58]\n",
      " [56 59]\n",
      " [57 60]\n",
      " [57 61]\n",
      " [58 65]\n",
      " [59 66]\n",
      " [60 63]\n",
      " [61 64]\n",
      " [62 63]\n",
      " [62 64]\n",
      " [65 66]\n",
      " [67 68]\n",
      " [67 69]\n",
      " [67 70]\n",
      " [69 71]\n",
      " [70 72]\n",
      " [71 73]\n",
      " [72 73]\n",
      " [75 97]\n",
      " [76 82]\n",
      " [76 86]\n",
      " [77 87]\n",
      " [78 88]\n",
      " [79 82]\n",
      " [79 87]\n",
      " [80 88]\n",
      " [80 94]\n",
      " [81 83]\n",
      " [81 84]\n",
      " [81 85]\n",
      " [82 85]\n",
      " [82 91]\n",
      " [83 87]\n",
      " [83 88]\n",
      " [84 86]\n",
      " [84 89]\n",
      " [86 90]\n",
      " [89 92]\n",
      " [90 93]\n",
      " [92 93]\n",
      " [94 95]\n",
      " [94 96]\n",
      " [95 98]\n",
      " [96 99]\n",
      " [97 98]\n",
      " [97 99]]\n",
      "node2grah\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "label [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# showing one batch:\n",
    "for train_batch in gen_batch(training_set, batch_size=4):\n",
    "    for k,v in train_batch[0].items():\n",
    "        print(k)\n",
    "        print(v)\n",
    "        pass\n",
    "    print('label', train_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet tf2_gnn\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
      "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
      "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " gnn (GNN)                      (None, 32)           161728      ['embedding[0][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
      " da)                                                              'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 171,761\n",
      "Trainable params: 171,761\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
    "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1\n",
    "\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "params = GNN.get_default_hyperparameters()\n",
    "\n",
    "# Attention aggregation mechanism\n",
    "# params[\"message_calculation_class\"] = \"rgat\"\n",
    "# params[\"num_heads\"] = 8\n",
    "\n",
    "# GGNN aggregation mechanism\n",
    "# params[\"message_calculation_class\"] = \"ggnn\"\n",
    "\n",
    "# GGNN aggregation mechanism\n",
    "params[\"message_calculation_class\"] = \"gnn_film\"\n",
    "params[\"film_parameter_MLP_hidden_layers\"] = 8\n",
    "\n",
    "params[\"hidden_dim\"] = 32\n",
    "gnn_layer = GNN(params)\n",
    "gnn_out = gnn_layer(gnn_input)\n",
    "\n",
    "print('gnn_out', gnn_out)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    ")\n",
    "print('mean:', avg)\n",
    "\n",
    "pred = Dense(1, activation='sigmoid')(avg)\n",
    "print('pred:', pred)\n",
    "\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data,\n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_3_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_3_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_3_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/concat_3:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/concat_2:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm_2/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/gnn__fi_lm/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 15s 18ms/step - loss: 0.2709 - auc: 0.4039 - val_loss: 0.1864 - val_auc: 0.5494\n",
      "Epoch 2/25\n",
      "665/665 [==============================] - 12s 18ms/step - loss: 0.2071 - auc: 0.5695 - val_loss: 0.2328 - val_auc: 0.6391\n",
      "Epoch 3/25\n",
      "665/665 [==============================] - 12s 18ms/step - loss: 0.2004 - auc: 0.6245 - val_loss: 0.1679 - val_auc: 0.7328\n",
      "Epoch 4/25\n",
      "665/665 [==============================] - 12s 19ms/step - loss: 0.1949 - auc: 0.6413 - val_loss: 0.1796 - val_auc: 0.7486\n",
      "Epoch 5/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1938 - auc: 0.6564 - val_loss: 0.1875 - val_auc: 0.7623\n",
      "Epoch 6/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1916 - auc: 0.6649 - val_loss: 0.2221 - val_auc: 0.6973\n",
      "Epoch 7/25\n",
      "665/665 [==============================] - 14s 20ms/step - loss: 0.1902 - auc: 0.6724 - val_loss: 0.1530 - val_auc: 0.7803\n",
      "Epoch 8/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1858 - auc: 0.7001 - val_loss: 0.1549 - val_auc: 0.7913\n",
      "Epoch 9/25\n",
      "665/665 [==============================] - 14s 20ms/step - loss: 0.1865 - auc: 0.6977 - val_loss: 0.1756 - val_auc: 0.7769\n",
      "Epoch 10/25\n",
      "665/665 [==============================] - 14s 20ms/step - loss: 0.1828 - auc: 0.7158 - val_loss: 0.1573 - val_auc: 0.7840\n",
      "Epoch 11/25\n",
      "665/665 [==============================] - 14s 21ms/step - loss: 0.1815 - auc: 0.7297 - val_loss: 0.1609 - val_auc: 0.7984\n",
      "Epoch 12/25\n",
      "665/665 [==============================] - 14s 20ms/step - loss: 0.1809 - auc: 0.7256 - val_loss: 0.1458 - val_auc: 0.8160\n",
      "Epoch 13/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1817 - auc: 0.7266 - val_loss: 0.1596 - val_auc: 0.7856\n",
      "Epoch 14/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1812 - auc: 0.7221 - val_loss: 0.1597 - val_auc: 0.7729\n",
      "Epoch 15/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1834 - auc: 0.7142 - val_loss: 0.1469 - val_auc: 0.8072\n",
      "Epoch 16/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1831 - auc: 0.7082 - val_loss: 0.1669 - val_auc: 0.7119\n",
      "Epoch 17/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1803 - auc: 0.7254 - val_loss: 0.2101 - val_auc: 0.7607\n",
      "Epoch 18/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1811 - auc: 0.7284 - val_loss: 0.1473 - val_auc: 0.7851\n",
      "Epoch 19/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1798 - auc: 0.7294 - val_loss: 0.1634 - val_auc: 0.8064\n",
      "Epoch 20/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1797 - auc: 0.7257 - val_loss: 0.1718 - val_auc: 0.7735\n",
      "Epoch 21/25\n",
      "665/665 [==============================] - 13s 19ms/step - loss: 0.1813 - auc: 0.7184 - val_loss: 0.1503 - val_auc: 0.7723\n",
      "Epoch 22/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1835 - auc: 0.7033 - val_loss: 0.1397 - val_auc: 0.8069\n",
      "Epoch 23/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1779 - auc: 0.7402 - val_loss: 0.1559 - val_auc: 0.7968\n",
      "Epoch 24/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1780 - auc: 0.7308 - val_loss: 0.1545 - val_auc: 0.8032\n",
      "Epoch 25/25\n",
      "665/665 [==============================] - 13s 20ms/step - loss: 0.1788 - auc: 0.7329 - val_loss: 0.1696 - val_auc: 0.7550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ed8e1abb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 32\n",
    "num_batchs = math.ceil(len(training_set) / batch_size)\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
    "\n",
    "model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=25,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(\n",
    "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
    ")\n",
    "y_pred = np.reshape(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "submission = pd.DataFrame({'label':y_pred})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('sample_submission_rgat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
